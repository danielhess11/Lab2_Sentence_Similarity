{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpFFwJdnlwu0"
      },
      "source": [
        "# Lab 2: ?\n",
        "\n",
        "Lab session by:\n",
        "* Daniel Hess\n",
        "* Pandelis Laurens Symeonidis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adiqj_xHmim9"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BELigkBzmjO_"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.metrics.distance import jaccard_distance\n",
        "from scipy.stats import pearsonr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS_cHxJ0mwMM"
      },
      "source": [
        "-there are some shortcomings in this approach, for instance if we consider the tokens the uppcercase version and lowercase version will be two diff tokens so we can check if we are getting better results with everyhting lowercase or not\n",
        "\n",
        "- what does stopword mean? Its a word with no meaning, if we add words with no meaning with same wiehghts as rest of the tokens then the metric can be poisoned, so we can try to remove the stopwords (include this in analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "jBsaaNqynry1",
        "outputId": "fd5388e5-8101-46de-b6e3-e95568e17569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    0.653846\n",
            "1    0.214286\n",
            "2    0.608696\n",
            "3    0.454545\n",
            "4    0.000000\n",
            "dtype: float64\n",
            "(459,)\n",
            "0.4504977169318686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/pandelissymeonidis/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "dt = pd.read_csv('./STS.input.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "dt_tokenized = dt.map(nltk.word_tokenize)\n",
        "dt_tokenized.head()\n",
        "\n",
        "jaccard_distances = dt_tokenized.apply(lambda row: jaccard_distance(set(row[0]), set(row[1])), axis=1)\n",
        "print(jaccard_distances.head())\n",
        "\n",
        "\n",
        "similarity_scores = 1 - jaccard_distances\n",
        "print(similarity_scores.shape)\n",
        "\n",
        "gold_standard_dt = pd.read_csv('./STS.gs.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "\n",
        "comparison = pearsonr(similarity_scores, gold_standard_dt[0])\n",
        "print(comparison[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqYXjWjIpPX8"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yGMV5DxpR1_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
