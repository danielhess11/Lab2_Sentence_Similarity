{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f832d5ea",
   "metadata": {},
   "source": [
    "# Lab 8 Parsing\n",
    "\n",
    "Lab session by:\n",
    "* Daniel Hess\n",
    "* Pandelis Laurens Symeonidis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d837f0a",
   "metadata": {},
   "source": [
    "# **NOTES**\n",
    "chartparser (seen in class), can access other strategies using parameter of chartparser class or use the specific class (bottomup, leftcorner …) \n",
    "\n",
    "viterbi parser → will not find all solutions only optimal but will find very quick\n",
    "\n",
    "order matters\n",
    "\n",
    "first rule should be whole sentence\n",
    "\n",
    "we can test different strategies\n",
    "\n",
    "exercise:\n",
    "\n",
    "given the sentence, expand (add rules to the grammar in the first slide) so the grammar can parse that sentence (dont add too specific rules)\n",
    "\n",
    "perform parsing using different strategies\n",
    "\n",
    "for each one of them print the returned trees, number of edges and list of explored edges.\n",
    "\n",
    "which parser is the most efficient based on the nr of edges that r explored\n",
    "\n",
    "which edges are filtered out by each strat and why. use edges method create a set and compare the edges that were explored and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9092fd4a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d658df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import BottomUpChartParser, BottomUpLeftCornerChartParser, LeftCornerChartParser\n",
    "from nltk import CFG\n",
    "from nltk.parse.util import Chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c76d8",
   "metadata": {},
   "source": [
    "# Define grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bc7bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar rules:\n",
      "\n",
      "S -> NP VP\n",
      "VP -> V NP\n",
      "VP -> V PP\n",
      "PP -> P NP\n",
      "NP -> NNS\n",
      "NP -> JJ NNS\n",
      "NP -> NP CC NP\n",
      "NNS -> 'cats'\n",
      "NNS -> 'dogs'\n",
      "NNS -> 'mice'\n",
      "NNS -> NNS CC NNS\n",
      "JJ -> 'big'\n",
      "JJ -> 'small'\n",
      "JJ -> 'lazy'\n",
      "CC -> 'and'\n",
      "CC -> 'or'\n",
      "P -> 'with'\n",
      "V -> 'play'\n",
      "V -> 'sleep'\n"
     ]
    }
   ],
   "source": [
    "grammar = CFG.fromstring('''\n",
    "  S   -> NP VP\n",
    "  VP -> V NP | V PP\n",
    "  PP -> P NP\n",
    "  NP  -> NNS | JJ NNS | NP CC NP\n",
    "  NNS -> \"cats\" | \"dogs\" | \"mice\" | NNS CC NNS \n",
    "  JJ  -> \"big\" | \"small\" | \"lazy\"\n",
    "  CC  -> \"and\" | \"or\"\n",
    "  P -> \"with\"\n",
    "  V -> \"play\" | \"sleep\"\n",
    "  ''')\n",
    "print(\"Grammar rules:\\n\")\n",
    "for prod in grammar.productions():\n",
    "    print(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf77836",
   "metadata": {},
   "source": [
    "# Helper function to run a parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8beff613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parser(parser_name, grammar, sentence):\n",
    "    if (parser_name == \"BottomUpChartParser\"):\n",
    "        parser_class = BottomUpChartParser\n",
    "    elif (parser_name == \"BottomUpLeftCornerChartParser\"):\n",
    "        parser_class = BottomUpLeftCornerChartParser\n",
    "    elif (parser_name == \"LeftCornerChartParser\"):\n",
    "        parser_class = LeftCornerChartParser\n",
    "\n",
    "    parser = parser_class(grammar)\n",
    "\n",
    "    chart = parser.chart_parse(sentence)\n",
    "    return chart\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ca154",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f7fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"lazy cats play with mice\".split()\n",
    "\n",
    "def analyse(chart: Chart):\n",
    "    trees = list(chart.parses(grammar.start()))\n",
    "    print(\"\\nParse trees:\")\n",
    "    if not trees:\n",
    "        print(\"  (no complete parse found)\")\n",
    "    else:\n",
    "        for i, t in enumerate(trees, start=1):\n",
    "            print(f\"\\nTree {i}:\")\n",
    "            print(t)\n",
    "\n",
    "    edges = list(chart.edges())\n",
    "    print(f\"\\nNumber of edges: {len(edges)}\")\n",
    "\n",
    "    print(\"\\nExplored edges:\")\n",
    "    for e in edges:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642f6598",
   "metadata": {},
   "source": [
    "# Bottom Up Chart Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a41ab05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse trees:\n",
      "\n",
      "Tree 1:\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (V play) (PP (P with) (NP (NNS mice)))))\n",
      "\n",
      "Number of edges: 48\n",
      "\n",
      "Explored edges:\n",
      "[0:1] 'lazy'\n",
      "[1:2] 'cats'\n",
      "[2:3] 'play'\n",
      "[3:4] 'with'\n",
      "[4:5] 'mice'\n",
      "[0:0] JJ -> * 'lazy'\n",
      "[0:1] JJ -> 'lazy' *\n",
      "[0:0] NP -> * JJ NNS\n",
      "[0:1] NP -> JJ * NNS\n",
      "[1:1] NNS -> * 'cats'\n",
      "[1:2] NNS -> 'cats' *\n",
      "[1:1] NP -> * NNS\n",
      "[1:1] NNS -> * NNS CC NNS\n",
      "[0:2] NP -> JJ NNS *\n",
      "[1:2] NP -> NNS *\n",
      "[1:2] NNS -> NNS * CC NNS\n",
      "[1:1] S  -> * NP VP\n",
      "[1:1] NP -> * NP CC NP\n",
      "[1:2] S  -> NP * VP\n",
      "[1:2] NP -> NP * CC NP\n",
      "[0:0] S  -> * NP VP\n",
      "[0:0] NP -> * NP CC NP\n",
      "[0:2] S  -> NP * VP\n",
      "[0:2] NP -> NP * CC NP\n",
      "[2:2] V  -> * 'play'\n",
      "[2:3] V  -> 'play' *\n",
      "[2:2] VP -> * V NP\n",
      "[2:2] VP -> * V PP\n",
      "[2:3] VP -> V * NP\n",
      "[2:3] VP -> V * PP\n",
      "[3:3] P  -> * 'with'\n",
      "[3:4] P  -> 'with' *\n",
      "[3:3] PP -> * P NP\n",
      "[3:4] PP -> P * NP\n",
      "[4:4] NNS -> * 'mice'\n",
      "[4:5] NNS -> 'mice' *\n",
      "[4:4] NP -> * NNS\n",
      "[4:4] NNS -> * NNS CC NNS\n",
      "[4:5] NP -> NNS *\n",
      "[4:5] NNS -> NNS * CC NNS\n",
      "[4:4] S  -> * NP VP\n",
      "[4:4] NP -> * NP CC NP\n",
      "[3:5] PP -> P NP *\n",
      "[4:5] S  -> NP * VP\n",
      "[4:5] NP -> NP * CC NP\n",
      "[2:5] VP -> V PP *\n",
      "[1:5] S  -> NP VP *\n",
      "[0:5] S  -> NP VP *\n"
     ]
    }
   ],
   "source": [
    "parse_bottom_up = run_parser(\"BottomUpChartParser\", grammar, sentence)\n",
    "analyse(parse_bottom_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4707007",
   "metadata": {},
   "source": [
    "# Bottom Up Left Corner Chart Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "733e54ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse trees:\n",
      "\n",
      "Tree 1:\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (V play) (PP (P with) (NP (NNS mice)))))\n",
      "\n",
      "Number of edges: 29\n",
      "\n",
      "Explored edges:\n",
      "[0:1] 'lazy'\n",
      "[1:2] 'cats'\n",
      "[2:3] 'play'\n",
      "[3:4] 'with'\n",
      "[4:5] 'mice'\n",
      "[0:1] JJ -> 'lazy' *\n",
      "[0:1] NP -> JJ * NNS\n",
      "[1:2] NNS -> 'cats' *\n",
      "[1:2] NP -> NNS *\n",
      "[1:2] NNS -> NNS * CC NNS\n",
      "[0:2] NP -> JJ NNS *\n",
      "[0:2] S  -> NP * VP\n",
      "[0:2] NP -> NP * CC NP\n",
      "[1:2] S  -> NP * VP\n",
      "[1:2] NP -> NP * CC NP\n",
      "[2:3] V  -> 'play' *\n",
      "[2:3] VP -> V * NP\n",
      "[2:3] VP -> V * PP\n",
      "[3:4] P  -> 'with' *\n",
      "[3:4] PP -> P * NP\n",
      "[4:5] NNS -> 'mice' *\n",
      "[4:5] NP -> NNS *\n",
      "[4:5] NNS -> NNS * CC NNS\n",
      "[4:5] S  -> NP * VP\n",
      "[4:5] NP -> NP * CC NP\n",
      "[3:5] PP -> P NP *\n",
      "[2:5] VP -> V PP *\n",
      "[0:5] S  -> NP VP *\n",
      "[1:5] S  -> NP VP *\n"
     ]
    }
   ],
   "source": [
    "parse_bottom_up_left_corner = run_parser(\"BottomUpLeftCornerChartParser\", grammar, sentence)\n",
    "analyse(parse_bottom_up_left_corner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafca940",
   "metadata": {},
   "source": [
    "# Left Corner Chart Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049fd41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse trees:\n",
      "\n",
      "Tree 1:\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (V play) (PP (P with) (NP (NNS mice)))))\n",
      "\n",
      "Number of edges: 22\n",
      "\n",
      "Explored edges:\n",
      "[0:1] 'lazy'\n",
      "[1:2] 'cats'\n",
      "[2:3] 'play'\n",
      "[3:4] 'with'\n",
      "[4:5] 'mice'\n",
      "[0:1] JJ -> 'lazy' *\n",
      "[0:1] NP -> JJ * NNS\n",
      "[1:2] NNS -> 'cats' *\n",
      "[1:2] NP -> NNS *\n",
      "[0:2] NP -> JJ NNS *\n",
      "[0:2] S  -> NP * VP\n",
      "[1:2] S  -> NP * VP\n",
      "[2:3] V  -> 'play' *\n",
      "[2:3] VP -> V * PP\n",
      "[3:4] P  -> 'with' *\n",
      "[3:4] PP -> P * NP\n",
      "[4:5] NNS -> 'mice' *\n",
      "[4:5] NP -> NNS *\n",
      "[3:5] PP -> P NP *\n",
      "[2:5] VP -> V PP *\n",
      "[0:5] S  -> NP VP *\n",
      "[1:5] S  -> NP VP *\n"
     ]
    }
   ],
   "source": [
    "parse_left_corner = run_parser(\"LeftCornerChartParser\", grammar, sentence)\n",
    "analyse(parse_left_corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04237815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Edges only in BottomUp (not in BottomUpLeftCorner): 19\n",
      "   [0:0] JJ -> * 'lazy'\n",
      "   [0:0] NP -> * JJ NNS\n",
      "   [0:0] NP -> * NP CC NP\n",
      "   [0:0] S  -> * NP VP\n",
      "   [1:1] NNS -> * 'cats'\n",
      "   [1:1] NNS -> * NNS CC NNS\n",
      "   [1:1] NP -> * NNS\n",
      "   [1:1] NP -> * NP CC NP\n",
      "   [1:1] S  -> * NP VP\n",
      "   [2:2] V  -> * 'play'\n",
      "   [2:2] VP -> * V NP\n",
      "   [2:2] VP -> * V PP\n",
      "   [3:3] P  -> * 'with'\n",
      "   [3:3] PP -> * P NP\n",
      "   [4:4] NNS -> * 'mice'\n",
      "   [4:4] NNS -> * NNS CC NNS\n",
      "   [4:4] NP -> * NNS\n",
      "   [4:4] NP -> * NP CC NP\n",
      "   [4:4] S  -> * NP VP\n",
      "\n",
      "Edges only in BottomUpLeftCorner (not in BottomUp): 0\n",
      "\n",
      "Edges only in BottomUp (not in LeftCorner): 26\n",
      "   [0:0] JJ -> * 'lazy'\n",
      "   [0:0] NP -> * JJ NNS\n",
      "   [0:0] NP -> * NP CC NP\n",
      "   [0:0] S  -> * NP VP\n",
      "   [0:2] NP -> NP * CC NP\n",
      "   [1:1] NNS -> * 'cats'\n",
      "   [1:1] NNS -> * NNS CC NNS\n",
      "   [1:1] NP -> * NNS\n",
      "   [1:1] NP -> * NP CC NP\n",
      "   [1:1] S  -> * NP VP\n",
      "   [1:2] NNS -> NNS * CC NNS\n",
      "   [1:2] NP -> NP * CC NP\n",
      "   [2:2] V  -> * 'play'\n",
      "   [2:2] VP -> * V NP\n",
      "   [2:2] VP -> * V PP\n",
      "   [2:3] VP -> V * NP\n",
      "   [3:3] P  -> * 'with'\n",
      "   [3:3] PP -> * P NP\n",
      "   [4:4] NNS -> * 'mice'\n",
      "   [4:4] NNS -> * NNS CC NNS\n",
      "   [4:4] NP -> * NNS\n",
      "   [4:4] NP -> * NP CC NP\n",
      "   [4:4] S  -> * NP VP\n",
      "   [4:5] NNS -> NNS * CC NNS\n",
      "   [4:5] NP -> NP * CC NP\n",
      "   [4:5] S  -> NP * VP\n",
      "\n",
      "Edges only in LeftCorner (not in BottomUp): 0\n",
      "\n",
      "Edges only in BottomUpLeftCorner (not in LeftCorner): 7\n",
      "   [0:2] NP -> NP * CC NP\n",
      "   [1:2] NNS -> NNS * CC NNS\n",
      "   [1:2] NP -> NP * CC NP\n",
      "   [2:3] VP -> V * NP\n",
      "   [4:5] NNS -> NNS * CC NNS\n",
      "   [4:5] NP -> NP * CC NP\n",
      "   [4:5] S  -> NP * VP\n",
      "\n",
      "Edges only in LeftCorner (not in BottomUpLeftCorner): 0\n"
     ]
    }
   ],
   "source": [
    "parsers_edges = {\n",
    "    \"BottomUp\": set(parse_bottom_up.edges()),\n",
    "    \"BottomUpLeftCorner\": set(parse_bottom_up_left_corner.edges()),\n",
    "    \"LeftCorner\": set(parse_left_corner.edges()),\n",
    "}\n",
    "names = list(parsers_edges.keys())\n",
    "for i in range(len(names)):\n",
    "    for j in range(i + 1, len(names)):\n",
    "        n1, n2 = names[i], names[j]\n",
    "        e1, e2 = parsers_edges[n1], parsers_edges[n2]\n",
    "\n",
    "        only1 = e1 - e2\n",
    "        only2 = e2 - e1\n",
    "\n",
    "        print(f\"\\nEdges only in {n1} (not in {n2}): {len(only1)}\")\n",
    "        for e in sorted(only1, key=str):\n",
    "            print(\"  \", e)\n",
    "\n",
    "        print(f\"\\nEdges only in {n2} (not in {n1}): {len(only2)}\")\n",
    "        for e in sorted(only2, key=str):\n",
    "            print(\"  \", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea512fd",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "## Chart Parsing Strategies: Efficiency and Filtering Analysis\n",
    "\n",
    "### Overview\n",
    "This exercise was to create a set of grammar rules capable of parsing the sentence:\n",
    "**lazy cats play with mice**\n",
    "\n",
    "Once the grammar includes adjectives, plural nouns, the verb play, and prepositional phrases, the sentence is parsed using three strategies\n",
    "\n",
    "* **BottomUpChartParser**\n",
    "* **BottomUpLeftCornerChartParser**\n",
    "* **LeftCornerChartParser**\n",
    "\n",
    "After this we examined the resulting parse tree, along with the number of edges explored and the specific edges that were generated during parsing. \n",
    "\n",
    "### Results summary\n",
    "\n",
    "All three parsers returned the same valid treee for the sentence. This means that the difference in this case is not in the result but in the computational work needed to get it. For this we can take a look at the number of explored edges.\n",
    "\n",
    "| Parser | # Explored Edges |\n",
    "| ----------- | ----------- |\n",
    "| BoottomUpChartParser | 48 |\n",
    "| BottomUpLeftCornerChartParser | 29 |\n",
    "| LeftCornerChartParser | 22 |\n",
    "\n",
    "Judging by how many edges are explored we can conclude that the LeftCornerChartParser is the most efficient.\n",
    "\n",
    "### Key Findings\n",
    "By comparing the sets of edges between the parsers, we found that 19 additional edges are created by the Bottom-Up parser compared to Bottom-Up Left Corner and 26 more than the Left-Corner chart parser. Left-Corner combines bottom-up evidence, which reflects what has actually been read, with top-down constraints that restrict predictions. This makes it so that it filters out both the speculative predictions generated by the Bottom-Up parser and the locally plausible but globally impossible partial expansions that Bottom-Up Left Corner still allows (such as NP → NP * CC NP or VP → V * NP when the continuation does not match the input). This filtering makes Left-Corner the most efficient strategy, exploring only edges that can contribute to a valid full parse.\n",
    "\n",
    "### Conclusions\n",
    "This lab showed that\n",
    "* All three parsers successfully generate the same parse tree, but differ in efficiency.\n",
    "* Bottom-Up parsing explores the largest number of edges because it predicts every possible rule at every position, regardless of global structure.\n",
    "* Bottom-Up Left-Corner improves efficiency by restricting predictions based on valid left corners (only symbols that can appear at beginning).\n",
    "* Left-Corner parsing is the most efficient, exploring less than half as many edges than Bottom-Up.\n",
    "\n",
    "The combination of top-down and bottom-up constraints prevents both irrelevant predictions and locally plausible but globally impossible partial parses, making it the most efficient out of the three."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
