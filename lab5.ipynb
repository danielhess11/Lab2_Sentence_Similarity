{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc3fb90",
   "metadata": {},
   "source": [
    "# Lab 5: \n",
    "\n",
    "Lab session by:\n",
    "* Daniel Hess\n",
    "* Pandelis Laurens Symeonidis\n",
    "\n",
    "map from postag to wordnet postag only words adj, nouns and adverbs\n",
    "\n",
    "Get most frequent wordnet synset\n",
    "mfs = most frequent wordnet synset is the first synset returned by wn.synset(w, t)\n",
    "synsets are ordered by frequency, so this is easy, calling the count method on the lemma we can confirm it\n",
    "lemmas have a count method telling us how many times they are in the corpus (wordnet)\n",
    "\n",
    "using the synset found \n",
    "\n",
    "find the lowest common hypernim, aka least common subsumer, \n",
    "\n",
    "normalize similarities!!!!! FIND THE BOUNDS (RESEARCH IT), checking src code\n",
    "Caviat: depth is precomputed and each tree (telling depth) is for each pos tag, depending on the pos tag the upper/lower bound\n",
    "simulate-root/create common node/such that they are from the same tree\n",
    "\n",
    "Which is the best similarity, a similarity metric should meet certain criteria (the best meets all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73cded5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\Daniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet_ic')\n",
    "\n",
    "from nltk.corpus import wordnet_ic, wordnet as wn\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b5bde3",
   "metadata": {},
   "source": [
    "### Penn tag to Wordnet mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35f80fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(word: str, penn_tag: str):\n",
    "\n",
    "    d = {'NN': 'n', 'NNS': 'n',\n",
    "          'JJ': 'a', 'JJR': 'a', 'JJS': 'a',\n",
    "            'VB': 'v', 'VBD': 'v', 'VBG': 'v', 'VBN': 'v', 'VBP': 'v', 'VBZ': 'v', \n",
    "            'RB': 'r', 'RBR': 'r', 'RBS': 'r'} \n",
    "    \n",
    "    if penn_tag in d: \n",
    "        return word, d[penn_tag]\n",
    "    else:\n",
    "        return word, None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245cec5b",
   "metadata": {},
   "source": [
    "### Step 1 Convert penn -> wordnet (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "698dfc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('man', 'n'), ('swim', 'v'), ('girl', 'n'), ('boy', 'n'), ('woman', 'n'), ('walk', 'v')]\n"
     ]
    }
   ],
   "source": [
    "pairs_penn = [('the','DT'), ('man','NN'), ('swim','VB'), ('with', 'PR'), ('a', 'DT'),\n",
    "('girl','NN'), ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), ('whilst', 'PR'),\n",
    "('the', 'DT'), ('woman', 'NN'), ('walk', 'VB')]\n",
    "\n",
    "converted = [convert(w, t) for w, t in pairs_penn]\n",
    "pairs_wn = [pair for pair in converted if pair[1]] # If pos = None, it is not indexed by wordnet\n",
    "print(pairs_wn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be011522",
   "metadata": {},
   "source": [
    "### Step 2 compute most frequenst synset for each word and confirm it is the most frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f122239f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('man.n.01'), Synset('swim.v.01'), Synset('girl.n.01'), Synset('male_child.n.01'), Synset('woman.n.01'), Synset('walk.v.01')]\n"
     ]
    }
   ],
   "source": [
    "synsets = [wn.synsets(lemma=w, pos=t)[0] for w, t in pairs_wn] # Compute most frequent synset AKA synsets[0] as they are ordered by frequency\n",
    "print(synsets)\n",
    "\n",
    "# TODO: proffessor asked us to use .count() just to confirm that the synsets[0] is the most frequent (even though it is he wants us to confirm it)'\n",
    "# Yes he was that vague about it\n",
    "# Nope idk how to do it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea747d",
   "metadata": {},
   "source": [
    "### Step 3 Compute the least common hypernim whenever possible\n",
    "(It is not possible to do it when pos1!=pos2, cant get common hypernim of a verb vs noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a366889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man[man.n.01] ~ girl[girl.n.01] -> LCH: adult.n.01 (depth=7)\n",
      "man[man.n.01] ~ boy[male_child.n.01] -> LCH: male.n.02 (depth=7)\n",
      "man[man.n.01] ~ woman[woman.n.01] -> LCH: adult.n.01 (depth=7)\n",
      "swim[swim.v.01] ~ walk[walk.v.01] -> LCH: travel.v.01 (depth=0)\n",
      "girl[girl.n.01] ~ boy[male_child.n.01] -> LCH: person.n.01 (depth=6)\n",
      "girl[girl.n.01] ~ woman[woman.n.01] -> LCH: woman.n.01 (depth=8)\n",
      "boy[male_child.n.01] ~ woman[woman.n.01] -> LCH: person.n.01 (depth=6)\n"
     ]
    }
   ],
   "source": [
    "content = [(w, t, wn.synsets(lemma=w, pos=t)[0]) for w, t, in pairs_wn]\n",
    "\n",
    "def depth(syn):\n",
    "    # depth = longest hypernym path length minus 1 (root=0)\n",
    "    return max(len(p) for p in syn.hypernym_paths()) - 1\n",
    "\n",
    "results = []\n",
    "for (w1, pos1, s1), (w2, pos2, s2) in combinations(content, 2):\n",
    "    if pos1 != pos2:\n",
    "        continue  # nouns with nouns, verbs with verbs\n",
    "    lchs = s1.lowest_common_hypernyms(s2)\n",
    "    lch = max(lchs, key=depth) if lchs else None\n",
    "    print(f\"{w1}[{s1.name()}] ~ {w2}[{s2.name()}] -> LCH: {lch.name()} (depth={depth(lch)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608a3e6",
   "metadata": {},
   "source": [
    "## Another Way of checking best lch, not deepest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbc98ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man[man.n.01] ~ girl[girl.n.01] -> LCH: adult.n.01 (depth=7)\n",
      "man[man.n.01] ~ boy[boy.n.02] -> LCH: man.n.01 (depth=8)\n",
      "man[man.n.01] ~ woman[woman.n.01] -> LCH: adult.n.01 (depth=7)\n",
      "swim[swim.v.01] ~ walk[walk.v.01] -> LCH: travel.v.01 (depth=0)\n",
      "girl[daughter.n.01] ~ boy[son.n.01] -> LCH: child.n.02 (depth=9)\n",
      "girl[girl.n.01] ~ woman[woman.n.01] -> LCH: woman.n.01 (depth=8)\n",
      "boy[boy.n.02] ~ woman[woman.n.01] -> LCH: adult.n.01 (depth=7)\n"
     ]
    }
   ],
   "source": [
    "def best_lch(word1, pos1, word2, pos2):\n",
    "    syns1 = wn.synsets(word1, pos1)\n",
    "    syns2 = wn.synsets(word2, pos2)\n",
    "    best = None\n",
    "    best_score = -1\n",
    "    for s1, s2 in product(syns1, syns2):\n",
    "        lchs = s1.lowest_common_hypernyms(s2)\n",
    "        if not lchs: \n",
    "            continue\n",
    "        lch = max(lchs, key=depth)\n",
    "        if depth(lch) > best_score:\n",
    "            best = (s1, s2, lch)\n",
    "            best_score = depth(lch)\n",
    "    return best \n",
    "\n",
    "for (w1,p1),(w2,p2) in combinations([(w,p) for w,p,_ in content], 2):\n",
    "    if p1 != p2: \n",
    "        continue\n",
    "    res = best_lch(w1,p1,w2,p2)\n",
    "    if not res: \n",
    "        continue\n",
    "    s1, s2, lch = res\n",
    "    print(f\"{w1}[{s1.name()}] ~ {w2}[{s2.name()}] -> LCH: {lch.name()} (depth={depth(lch)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b19675",
   "metadata": {},
   "source": [
    "### Step 4 compute similarity between pairs (when possible aka pos1=pos2) using 4 different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b1ba57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man[man.n.01] ~ girl[girl.n.01]\n",
      "  path=0.250  lch=2.251  wup=0.632  lin=0.714\n",
      "\n",
      "man[man.n.01] ~ boy[male_child.n.01]\n",
      "  path=0.333  lch=2.539  wup=0.667  lin=0.729\n",
      "\n",
      "man[man.n.01] ~ woman[woman.n.01]\n",
      "  path=0.333  lch=2.539  wup=0.667  lin=0.787\n",
      "\n",
      "swim[swim.v.01] ~ walk[walk.v.01]\n",
      "  path=0.333  lch=2.159  wup=0.333  lin=0.491\n",
      "\n",
      "girl[girl.n.01] ~ boy[male_child.n.01]\n",
      "  path=0.167  lch=1.846  wup=0.632  lin=0.293\n",
      "\n",
      "girl[girl.n.01] ~ woman[woman.n.01]\n",
      "  path=0.500  lch=2.944  wup=0.632  lin=0.907\n",
      "\n",
      "boy[male_child.n.01] ~ woman[woman.n.01]\n",
      "  path=0.200  lch=2.028  wup=0.667  lin=0.318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "def fmt(x, nd=3):\n",
    "    return \"â€”\" if x is None else f\"{x:.{nd}f}\"\n",
    "\n",
    "\n",
    "for (w1, pos1, s1), (w2, pos2, s2) in combinations(content, 2):\n",
    " \n",
    "    if pos1 != pos2:\n",
    "        continue\n",
    "\n",
    "    path = s1.path_similarity(s2)\n",
    "    try:\n",
    "        lch = s1.lch_similarity(s2)\n",
    "    except Exception:\n",
    "        lch = None\n",
    "    wup = s1.wup_similarity(s2)\n",
    "    try:\n",
    "        lin = s1.lin_similarity(s2, brown_ic) if p1 in ('n', 'v') else None\n",
    "    except Exception:\n",
    "        lin = None\n",
    "\n",
    "\n",
    "    print(f\"{w1}[{s1.name()}] ~ {w2}[{s2.name()}]\")\n",
    "    print(f\"  path={path:.3f}  lch={lch:.3f}  wup={wup:.3f}  lin={lin:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ee9a9",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8d1b9",
   "metadata": {},
   "source": [
    "- Confirm that synsets[0] is most frequent, by using .count() on the lemma (not very sure what that means)\n",
    "- Normalize similarities of each method so that they are comparable\n",
    "- Why does the least common hypernym sometimes not make sense (depending on which sense/synset you use) -> not the same comparing man v.s boy and man v.s male_child\n",
    "- Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6a02a",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879161f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
