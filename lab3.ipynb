{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0095cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0  \\\n",
      "0  [The, leaders, have, now, been, given, a, new,...   \n",
      "1  [Amendment, No, 7, proposes, certain, changes,...   \n",
      "2  [Let, me, remind, you, that, our, allies, incl...   \n",
      "3  [The, vote, will, take, place, today, at, 5.30...   \n",
      "4  [The, fishermen, are, inactive, ,, tired, and,...   \n",
      "\n",
      "                                                   1  \n",
      "0  [The, leaders, benefit, aujourd, ', hui, of, a...  \n",
      "1  [Amendment, No, 7, is, proposing, certain, cha...  \n",
      "2  [I, would, like, to, remind, you, that, among,...  \n",
      "3         [The, vote, will, take, place, at, 5.30pm]  \n",
      "4  [The, fishermen, are, inactive, ,, tired, and,...  \n",
      "                                                   0  \\\n",
      "0  [The, leader, have, now, be, give, a, new, cha...   \n",
      "1  [Amendment, No, 7, propose, certain, change, i...   \n",
      "2  [Let, me, remind, you, that, our, ally, includ...   \n",
      "3  [The, vote, will, take, place, today, at, 5.30...   \n",
      "4  [The, fisherman, be, inactive, ,, tired, and, ...   \n",
      "\n",
      "                                                   1  \n",
      "0  [The, leader, benefit, aujourd, ', hui, of, a,...  \n",
      "1  [Amendment, No, 7, be, propose, certain, chang...  \n",
      "2  [I, would, like, to, remind, you, that, among,...  \n",
      "3         [The, vote, will, take, place, at, 5.30pm]  \n",
      "4  [The, fisherman, be, inactive, ,, tired, and, ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/pandelissymeonidis/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/pandelissymeonidis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/pandelissymeonidis/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# Download corpus\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "dt = pd.read_csv('./STS.input.SMTeuroparl.txt',sep='\\t',header=None)\n",
    "gold_standard_dt = pd.read_csv('./STS.gs.SMTeuroparl.txt',sep='\\t',header=None)\n",
    "\n",
    "dt = dt.map(nltk.word_tokenize)\n",
    "dt = dt.map(nltk.pos_tag)\n",
    "\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize(p):\n",
    "  d = {'NN': 'n', 'NNS': 'n', \n",
    "       'JJ': 'a', 'JJR': 'a', 'JJS': 'a', \n",
    "       'VB': 'v', 'VBD': 'v', 'VBG': 'v', 'VBN': 'v', 'VBP': 'v', 'VBZ': 'v', \n",
    "       'RB': 'r', 'RBR': 'r', 'RBS': 'r'}\n",
    "  \n",
    "  # decide what to do with the rest (this version ignores them)\n",
    "  if p[1] in d:\n",
    "    return wnl.lemmatize(p[0], pos=d[p[1]])\n",
    "  return p[0]\n",
    "\n",
    "dt = dt.map(lambda words: [lemmatize(word) for word in words])\n",
    "\n",
    "# when comparing should do the same preprocessing. If we do preprocessing before posttagger its wrong cause its trained on normal sentences. Order is important. If we want to apply the same preprocessing as previous session first tokenize and get post-tags and then we can apply anything we want.\n",
    "# list of post tags is different per model \n",
    "# will lemmas always be better? if we think no give counterexample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50b733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
